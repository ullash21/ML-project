{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "WBHE0s3jCfWV",
    "outputId": "57f21ee0-9270-4eb5-bfe8-75b334364057"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import gspread\n",
    "import requests \n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "#from pydrive.auth import GoogleAuth\n",
    "#from pydrive.drive import GoogleDrive\n",
    "#from google.colab import auth\n",
    "#from oauth2client.client import GoogleCredentials\n",
    "#auth.authenticate_user()\n",
    "#gauth = GoogleAuth()\n",
    "#gauth.credentials = GoogleCredentials.get_application_default()\n",
    "#drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    "Just run the individual lines of this notebook to run the files. Please take not to change the necessary directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=['AL','CN','EN','SG']\n",
    "def read(arr):\n",
    "    csvs=[]\n",
    "    for str in arr:\n",
    "        csvs.append(pd.read_csv('./'+str+'/train', low_memory=False, lineterminator ='\\n', delimiter = ' ', header = None,  names = ['Word', 'Tag']))\n",
    "    return csvs\n",
    "(ALdata,CNdata,ENdata,SGdata)=read(arr)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>小</td>\n",
       "      <td>B-DISTRICT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>港</td>\n",
       "      <td>I-DISTRICT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>四</td>\n",
       "      <td>B-POI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>方</td>\n",
       "      <td>I-POI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>家</td>\n",
       "      <td>I-POI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>园</td>\n",
       "      <td>I-POI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>B-HOUSENO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>幢</td>\n",
       "      <td>I-HOUSENO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1363</td>\n",
       "      <td>B-CELLNO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>室</td>\n",
       "      <td>I-CELLNO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>嘉</td>\n",
       "      <td>B-CITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>兴</td>\n",
       "      <td>I-CITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>南</td>\n",
       "      <td>B-DISTRICT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>湖</td>\n",
       "      <td>I-DISTRICT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>区</td>\n",
       "      <td>I-DISTRICT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word         Tag\n",
       "0      小  B-DISTRICT\n",
       "1      港  I-DISTRICT\n",
       "2      四       B-POI\n",
       "3      方       I-POI\n",
       "4      家       I-POI\n",
       "5      园       I-POI\n",
       "6     17   B-HOUSENO\n",
       "7      幢   I-HOUSENO\n",
       "8   1363    B-CELLNO\n",
       "9      室    I-CELLNO\n",
       "10     嘉      B-CITY\n",
       "11     兴      I-CITY\n",
       "12     南  B-DISTRICT\n",
       "13     湖  I-DISTRICT\n",
       "14     区  I-DISTRICT"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AL Train Data Set\n",
    "ALdata.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>这</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>大概</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>是</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>所有</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>版本</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>里</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>无忌</td>\n",
       "      <td>B-neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>哥哥</td>\n",
       "      <td>I-neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>对</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>敏敏</td>\n",
       "      <td>B-neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>说</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>过</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>的</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>最美</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>的</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word        Tag\n",
       "0     这          O\n",
       "1    大概          O\n",
       "2     是          O\n",
       "3    所有          O\n",
       "4    版本          O\n",
       "5     里          O\n",
       "6    无忌  B-neutral\n",
       "7    哥哥  I-neutral\n",
       "8     对          O\n",
       "9    敏敏  B-neutral\n",
       "10    说          O\n",
       "11    过          O\n",
       "12    的          O\n",
       "13   最美          O\n",
       "14    的          O"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CN Train Data Set\n",
    "CNdata.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Municipal</td>\n",
       "      <td>B-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bonds</td>\n",
       "      <td>I-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>are</td>\n",
       "      <td>B-VP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>generally</td>\n",
       "      <td>B-ADVP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>B-ADJP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bit</td>\n",
       "      <td>I-ADJP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>safer</td>\n",
       "      <td>I-ADJP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>than</td>\n",
       "      <td>B-PP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>corporate</td>\n",
       "      <td>B-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bonds</td>\n",
       "      <td>I-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>in</td>\n",
       "      <td>B-PP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a</td>\n",
       "      <td>B-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>recession</td>\n",
       "      <td>I-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>but</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word     Tag\n",
       "0   Municipal    B-NP\n",
       "1       bonds    I-NP\n",
       "2         are    B-VP\n",
       "3   generally  B-ADVP\n",
       "4           a  B-ADJP\n",
       "5         bit  I-ADJP\n",
       "6       safer  I-ADJP\n",
       "7        than    B-PP\n",
       "8   corporate    B-NP\n",
       "9       bonds    I-NP\n",
       "10         in    B-PP\n",
       "11          a    B-NP\n",
       "12  recession    I-NP\n",
       "13          ,       O\n",
       "14        but       O"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EN Train Data Set\n",
    "ENdata.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "colab_type": "code",
    "id": "Nr-MJEhN8YRn",
    "outputId": "06dd977f-eca7-4bd7-d9d6-86083065b3e3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>about</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>see</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adam</td>\n",
       "      <td>B-positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Levine</td>\n",
       "      <td>I-positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>probably</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>going</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>drop</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dead</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://t.co/MpRIS0FqSA</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Come</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Word         Tag\n",
       "0                       I'm           O\n",
       "1                     about           O\n",
       "2                        to           O\n",
       "3                       see           O\n",
       "4                      Adam  B-positive\n",
       "5                    Levine  I-positive\n",
       "6                       and           O\n",
       "7                       I'm           O\n",
       "8                  probably           O\n",
       "9                     going           O\n",
       "10                       to           O\n",
       "11                     drop           O\n",
       "12                     dead           O\n",
       "13  https://t.co/MpRIS0FqSA           O\n",
       "14                     Come           O"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SG Train Data Set\n",
    "SGdata.head(15)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print('EN:')\n",
    "print(ENdata['Tag'].value_counts())\n",
    "print('\\n')\n",
    "\n",
    "print('AL:')\n",
    "print(ALdata['Tag'].value_counts())\n",
    "print('\\n')\n",
    "\n",
    "print('CN:')\n",
    "print(CNdata['Tag'].value_counts())\n",
    "print('\\n')\n",
    "\n",
    "print('SG:')\n",
    "print(SGdata['Tag'].value_counts())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write a function that estimates the emission parameters from the training set using MLE (maximum likelihood estimation)\n",
    "# e(x|y) = Count (y -> x)/Count(y)\n",
    " \n",
    "def emissionEstimate(data, word, tag):\n",
    "    tagcheck = (data.Tag == tag)\n",
    "    y = tagcheck.sum()\n",
    "    xy = (data.Word[tagcheck] == word).sum()\n",
    "    \n",
    "    return xy/y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the words that appear less than k times in the training set with\n",
    "# special word token #UNK# before training. This leads to a \"modified training set\"\n",
    "# if a word does not appear in the \"modified training set\", we replace that with #UNK# as well\n",
    "# change k to whatever value you want\n",
    "def smooth(s):\n",
    "    return\n",
    "#Smoothing of EN\n",
    "#k = 3\n",
    "EN = pd.DataFrame(ENdata['Word'].value_counts()< 3)\n",
    "EN.apply(lambda val: val == True)\n",
    "k1 = EN.index[EN['Word'] == True].tolist()\n",
    "ENdata.loc[ENdata['Word'].isin(k1), 'Word'] = '#UNK#'\n",
    "#ENdata.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smoothing of AL\n",
    "AL = pd.DataFrame(ALdata['Word'].value_counts()<3)\n",
    "AL.apply(lambda val: val == True)\n",
    "k2 = AL.index[AL['Word'] == True].tolist()\n",
    "ALdata.loc[ALdata['Word'].isin(k2), 'Word'] = '#UNK#'\n",
    "#ALdata.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smoothing of CN\n",
    "CN = pd.DataFrame(CNdata['Word'].value_counts()<3)\n",
    "CN.apply(lambda val: val == True)\n",
    "k3 = CN.index[CN['Word'] == True].tolist()\n",
    "CNdata.loc[CNdata['Word'].isin(k3), 'Word'] = '#UNK#'\n",
    "#CNdata.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smoothing of SG\n",
    "SG = pd.DataFrame(SGdata['Word'].value_counts()<3)\n",
    "SG.apply(lambda val: val == True)\n",
    "k4 = SG.index[SG['Word'] == True].tolist()\n",
    "SGdata.loc[SGdata['Word'].isin(k4), 'Word'] = '#UNK#'\n",
    "#SGdata.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Obtain a dataset with Word, Tag, Emission\n",
    "\n",
    "Steps\n",
    "1) Obtain count of tags per word\n",
    "2) Find the Count of the different tags across the whole dataset\n",
    "3) For each tag for each word, find out what the total count for each tag\n",
    "4) Obtain emission count with Word, Tag, Emission by dividing step 1 and 4\n",
    "5) Keep only the word/tag with highest emission value\n",
    "\n",
    "Finally, export pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DUEdhx2HjdQq"
   },
   "outputs": [],
   "source": [
    "# Goal: Obtain a dataset with Word, Tag, Emission\n",
    "\n",
    "# Steps\n",
    "# 1) Obtain count of tags per word\n",
    "# 2) Find the Count of the different tags across the whole dataset\n",
    "# 3) For each tag for each word, find out what the total count for each tag\n",
    "# 4) Obtain emission count with Word, Tag, Emission by dividing step 1 and 4\n",
    "# 5) Keep only the word/tag with highest emission value\n",
    "\n",
    "#EN\n",
    "\n",
    "# 1)\n",
    "ENWordTagcount = pd.DataFrame({'Count' : ENdata.groupby(['Word', 'Tag']).size()}).reset_index()\n",
    "#ENWordTagcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2)\n",
    "ENTagcount = pd.DataFrame({'Global Count' :ENdata['Tag'].value_counts()}).reset_index()\n",
    "ENTagcount.rename(columns = {'index' : 'Tag'}, inplace= True)\n",
    "\n",
    "#ENTagcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "ENTotalTagCount = pd.merge(ENWordTagcount, ENTagcount, on='Tag')\n",
    "#ENTotalTagCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4)\n",
    "ENTotalTagCount['Emission'] = ENTotalTagCount['Count']/ENTotalTagCount['Global Count']\n",
    "#ENTotalTagCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5)\n",
    "idx = ENTotalTagCount.groupby(['Word'])['Emission'].transform(max) == ENTotalTagCount['Emission']\n",
    "ENmodel = ENTotalTagCount[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#open file\n",
    "\n",
    "#export file\n",
    "r = open(\"./EN/dev.in\",\"r\",encoding=\"utf8\")\n",
    "f = open(\"./EN/dev.p2.out\",\"w\",encoding=\"UTF-8\")\n",
    "\n",
    "ls = []\n",
    "for line in r.readlines():\n",
    "    if (line !='\\n'and line.strip('\\n') in ENmodel['Word']) : #check if word not newline and exist in model\n",
    "        f.write(line.strip('\\n')+ \" \" + ENmodel['Tag'].loc[ENmodel['Word']== line.strip('\\n')].item() + \"\\n\" )\n",
    "    elif (line !='\\n'): #check if word does not exist in model\n",
    "        f.write(line.strip('\\n')+ \" \" + ENmodel['Tag'].loc[ENmodel['Word']== \"#UNK#\"].item() + \"\\n\" )\n",
    "    else: #check if word is space\n",
    "        f.write(line)\n",
    "f.close()\n",
    "r.close()\n",
    "    \n",
    "    #ls.append(line.strip('\\n'))\n",
    "#print(r.readline())\n",
    "print(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: Obtain a dataset with Word, Tag, Emission\n",
    "\n",
    "# Steps\n",
    "# 1) Obtain count of tags per word\n",
    "# 2) Find the Count of the different tags across the whole dataset\n",
    "# 3) For each tag for each word, find out what the total count for each tag\n",
    "# 4) Obtain emission count with Word, Tag, Emission by dividing step 1 and 4\n",
    "# 5) Keep only the word/tag with highest emission value\n",
    "\n",
    "#AL\n",
    "\n",
    "# 1)\n",
    "ALWordTagcount = pd.DataFrame({'Count' : ALdata.groupby(['Word', 'Tag']).size()}).reset_index()\n",
    "#ALWordTagcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2)\n",
    "ALTagcount = pd.DataFrame({'Global Count' :ALdata['Tag'].value_counts()}).reset_index()\n",
    "ALTagcount.rename(columns = {'index' : 'Tag'}, inplace= True)\n",
    "\n",
    "#ALTagcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "ALTotalTagCount = pd.merge(ALWordTagcount, ALTagcount, on='Tag')\n",
    "#ALTotalTagCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4)\n",
    "ALTotalTagCount['Emission'] = ALTotalTagCount['Count']/ALTotalTagCount['Global Count']\n",
    "#ALTotalTagCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5)\n",
    "idx = ALTotalTagCount.groupby(['Word'])['Emission'].transform(max) == ALTotalTagCount['Emission']\n",
    "ALmodel = ALTotalTagCount[idx]\n",
    "#ALmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B-ASSIST'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALmodel['Tag'].loc[ALmodel['Word']=='400'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#open file\n",
    "r = open(\"./AL/dev.in\",\"r\",encoding=\"UTF-8\")\n",
    "f = open(\"./AL/dev.p2.out\",\"w\",encoding=\"UTF-8\")\n",
    "\n",
    "#export file\n",
    "\n",
    "for line in r.readlines():\n",
    "    if (line !='\\n'and line.strip('\\n') in ALmodel['Word']) : \n",
    "        f.write(line.strip('\\n')+ \" \" + ALmodel['Tag'].loc[ALmodel['Word']== line.strip('\\n')].item() + \"\\n\" )\n",
    "    elif (line !='\\n'):\n",
    "        f.write(line.strip('\\n')+ \" \" + ALmodel['Tag'].loc[ALmodel['Word']== \"#UNK#\"].item() + \"\\n\" )\n",
    "    else:\n",
    "        f.write(line)\n",
    "f.close()\n",
    "r.close()\n",
    "    \n",
    "    #ls.append(line.strip('\\n'))\n",
    "#print(r.readline())\n",
    "print(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: Obtain a dataset with Word, Tag, Emission\n",
    "\n",
    "# Steps\n",
    "# 1) Obtain count of tags per word\n",
    "# 2) Find the Count of the different tags across the whole dataset\n",
    "# 3) For each tag for each word, find out what the total count for each tag\n",
    "# 4) Obtain emission count with Word, Tag, Emission by dividing step 1 and 4\n",
    "# 5) Keep only the word/tag with highest emission value\n",
    "\n",
    "#CN\n",
    "\n",
    "# 1)\n",
    "CNWordTagcount = pd.DataFrame({'Count' : CNdata.groupby(['Word', 'Tag']).size()}).reset_index()\n",
    "#CNWordTagcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2)\n",
    "CNTagcount = pd.DataFrame({'Global Count' :CNdata['Tag'].value_counts()}).reset_index()\n",
    "CNTagcount.rename(columns = {'index' : 'Tag'}, inplace= True)\n",
    "\n",
    "#CNTagcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "CNTotalTagCount = pd.merge(CNWordTagcount, CNTagcount, on='Tag')\n",
    "#CNTotalTagCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4)\n",
    "CNTotalTagCount['Emission'] = CNTotalTagCount['Count']/CNTotalTagCount['Global Count']\n",
    "#CNTotalTagCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5)\n",
    "idx = CNTotalTagCount.groupby(['Word'])['Emission'].transform(max) == CNTotalTagCount['Emission']\n",
    "CNmodel = CNTotalTagCount[idx]\n",
    "#CNmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#open file\n",
    "#export file \n",
    "\n",
    "r = open(\"./CN/dev.in\",\"r\",encoding=\"utf8\")\n",
    "f = open(\"./CN/dev.p2.out\",\"w\",encoding=\"UTF-8\")\n",
    "\n",
    "ls = []\n",
    "for line in r.readlines():\n",
    "    if (line !='\\n'and line.strip('\\n') in CNmodel['Word']) : \n",
    "        f.write(line.strip('\\n')+ \" \" + CNmodel['Tag'].loc[CNmodel['Word']== line.strip('\\n')].item() + \"\\n\" )\n",
    "    elif (line !='\\n'):\n",
    "        f.write(line.strip('\\n')+ \" \" + CNmodel['Tag'].loc[CNmodel['Word']== \"#UNK#\"].item() + \"\\n\" )\n",
    "    else:\n",
    "        f.write(line)\n",
    "f.close()\n",
    "r.close()\n",
    "    \n",
    "    #ls.append(line.strip('\\n'))\n",
    "#print(r.readline())\n",
    "print(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: Obtain a dataset with Word, Tag, Emission\n",
    "\n",
    "# Steps\n",
    "# 1) Obtain count of tags per word\n",
    "# 2) Find the Count of the different tags across the whole dataset\n",
    "# 3) For each tag for each word, find out what the total count for each tag\n",
    "# 4) Obtain emission count with Word, Tag, Emission by dividing step 1 and 4\n",
    "# 5) Keep only the word/tag with highest emission value\n",
    "\n",
    "#SG\n",
    "\n",
    "# 1)\n",
    "SGWordTagcount = pd.DataFrame({'Count' : SGdata.groupby(['Word', 'Tag']).size()}).reset_index()\n",
    "#SGWordTagcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2)\n",
    "SGTagcount = pd.DataFrame({'Global Count' :SGdata['Tag'].value_counts()}).reset_index()\n",
    "SGTagcount.rename(columns = {'index' : 'Tag'}, inplace= True)\n",
    "\n",
    "#SGTagcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "SGTotalTagCount = pd.merge(SGWordTagcount, SGTagcount, on='Tag')\n",
    "#SGTotalTagCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4)\n",
    "SGTotalTagCount['Emission'] = SGTotalTagCount['Count']/SGTotalTagCount['Global Count']\n",
    "#SGTotalTagCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5)\n",
    "idx = SGTotalTagCount.groupby(['Word'])['Emission'].transform(max) == SGTotalTagCount['Emission']\n",
    "SGmodel = SGTotalTagCount[idx]\n",
    "#SGmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#open file\n",
    "#export file\n",
    "r = open(\"./SG/dev.in\",\"r\",encoding=\"utf8\")\n",
    "f = open(\"./SG/dev.p2.out\",\"w\",encoding=\"UTF-8\")\n",
    "\n",
    "ls = []\n",
    "for line in r.readlines():\n",
    "    if (line !='\\n'and line.strip('\\n') in SGmodel['Word']) : \n",
    "        f.write(line.strip('\\n')+ \" \" + SGmodel['Tag'].loc[SGmodel['Word']== line.strip('\\n')].item() + \"\\n\" )\n",
    "    elif (line !='\\n'):\n",
    "        f.write(line.strip('\\n')+ \" \" + SGmodel['Tag'].loc[SGmodel['Word']== \"#UNK#\"].item() + \"\\n\" )\n",
    "    else:\n",
    "        f.write(line)\n",
    "f.close()\n",
    "r.close()\n",
    "    \n",
    "    #ls.append(line.strip('\\n'))\n",
    "#print(r.readline())\n",
    "print(ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#Entity in gold data: 13179\n",
      "#Entity in prediction: 26131\n",
      "\n",
      "#Correct Entity : 7310\n",
      "Entity  precision: 0.2797\n",
      "Entity  recall: 0.5547\n",
      "Entity  F: 0.3719\n",
      "\n",
      "#Correct Sentiment : 1\n",
      "Sentiment  precision: 0.0000\n",
      "Sentiment  recall: 0.0001\n",
      "Sentiment  F: 0.0001\n"
     ]
    }
   ],
   "source": [
    "!py  ./EvalScript/evalResult.py ./EN/dev.out ./EN/dev.p2.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#Entity in gold data: 8408\n",
      "#Entity in prediction: 24663\n",
      "\n",
      "#Correct Entity : 926\n",
      "Entity  precision: 0.0375\n",
      "Entity  recall: 0.1101\n",
      "Entity  F: 0.0560\n",
      "\n",
      "#Correct Sentiment : 282\n",
      "Sentiment  precision: 0.0114\n",
      "Sentiment  recall: 0.0335\n",
      "Sentiment  F: 0.0171\n"
     ]
    }
   ],
   "source": [
    "!py   ./EvalScript/evalResult.py ./AL/dev.out ./AL/dev.p2.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#Entity in gold data: 1478\n",
      "#Entity in prediction: 23531\n",
      "\n",
      "#Correct Entity : 700\n",
      "Entity  precision: 0.0297\n",
      "Entity  recall: 0.4736\n",
      "Entity  F: 0.0560\n",
      "\n",
      "#Correct Sentiment : 63\n",
      "Sentiment  precision: 0.0027\n",
      "Sentiment  recall: 0.0426\n",
      "Sentiment  F: 0.0050\n"
     ]
    }
   ],
   "source": [
    "!py  ./EvalScript/evalResult.py ./CN/dev.out ./CN/dev.p2.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#Entity in gold data: 4537\n",
      "#Entity in prediction: 47656\n",
      "\n",
      "#Correct Entity : 2483\n",
      "Entity  precision: 0.0521\n",
      "Entity  recall: 0.5473\n",
      "Entity  F: 0.0951\n",
      "\n",
      "#Correct Sentiment : 572\n",
      "Sentiment  precision: 0.0120\n",
      "Sentiment  recall: 0.1261\n",
      "Sentiment  F: 0.0219\n"
     ]
    }
   ],
   "source": [
    "!py ./EvalScript/evalResult.py ./SG/dev.out ./SG/dev.p2.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "machine learning project",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
